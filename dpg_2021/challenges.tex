\begin{frame}{Challenges}
    \begin{block}{Different sizes of background processes}
        \begin{itemize}
            \item Dominating background can diminish the significance of secondary backgrounds in training
            \item Especially very signal-like backgrounds are likely to be mislabeled
        \end{itemize}
    \end{block}
    \begin{block}{Negative weights in Monte Carlo}
        \begin{itemize}
            \item Negative weights are needed in Monte Carlo generation to avoid double counting.
            \item In neural network training negative weights lead to an unwanted behaviour.
        \end{itemize}
    \end{block}
    \begin{block}{Accelerating network optimisation}
        \begin{itemize}
            \item Exploration of new features is only possible in an optimised network
            \item An evolutionary optimisation approach minimises the work effort
        \end{itemize}
    \end{block}
\end{frame}